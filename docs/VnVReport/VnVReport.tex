\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage{ragged2e}
\usepackage{float}
\usepackage{longtable}
\usepackage{makecell}
\usepackage{seqsplit}

\newcolumntype{L}[1]{>{\RaggedRight\arraybackslash}p{#1}}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
\AtBeginEnvironment{longtable}{\small}

\input{../Comments}
\input{../Common}

\begin{document}

\title{Verification and Validation Report: \progname} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
2025-03-10 & 1.0 & Initial version.\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{table}[h!]
  \vspace{5pt}
  \begin{tabular}{l l} 
    \toprule		
    \textbf{Symbol} & \textbf{Description} \\
    \midrule 
    CI & Continuous Integration. \\
    CMake & The build system used for configuring the project. \\
    ctest& CMake testing tool to execute unit tests. \\
    GHA & GitHub Actions. \\
    GTest & Google Test, a C++ unit testing framework. \\
    I/O & Input/Output. \\
    mXML & MusicXML. \\
    PDF & Portable Document Format. \\
    PCM\_16 & 16-bit Pulse-Code Modulation. \\
    SF\_INFO & A structure (from libsndfile) that holds data for file I/O. \\
    SRS & Software Requirements Specification. \\
    UI & User Interface. \\
    vcpkg & C++ dependency manager. \\
    WAV & Waveform Audio File Format. \\
    \bottomrule
  \end{tabular}\\
\end{table}
\newpage

\tableofcontents

\listoftables %if appropriate

\listoffigures %if appropriate

\newpage

\pagenumbering{arabic}

This document outlines the results of the 
\href{https://github.com/emilyperica/ScoreGen/blob/main/docs/VnVPlan/VnVPlan.pdf}{VnV plan}
executed for the development of an audio-to-sheet music generator. 
Functional and Nonfunctional Requirements Evaluations assess ScoreGen's 
adherence to system requirements as set out in the \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS} document. 
Unit Testing verifies the correctness of individual components, while Changes 
Due to Testing describes any modifications made in response to detected issues. 
The Automated Testing section details the integration of test suites to ensure 
consistent, continuous verification. Trace to Requirements and Trace to Modules 
ensure comphrensive validation by establishing clear connctions between test 
cases, software requirements, and system components. Finally, Code Coverage Metrics 
provide a quantitative analysis of test coverage.

\section{Functional Requirements Evaluation}
\label{fr}
Tests for the functional requirements of the application naturally follow the division of the major types of functional requirements
in section 9 of the \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. Thus, tests for each major 
type are grouped similarly, resulting in five subcategories.

  \subsection{Input Handling}
  \begin{enumerate}
    \item \textbf{Test for Correct Audio File Formats} \\
      \newline
      \textbf{Test ID:} FR-AR1-3-1 \\
      \textbf{Control:} Automatic \\
      \textbf{Initial State:} Application is running and idle, awaiting audio file upload from the user. \\
      \textbf{Input:} Audio file (e.g., \texttt{.WAV}, \texttt{.MP3}) \\
      \textbf{Expected Output:} File acceptance without errors, entrance into file processing state. \\
      \textbf{Actual Output:} \\
      \textbf{Test Case Derivation:} For validation of functional requirements FR-AR1 and FR-AR3 in section 9.1 of the 
      \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
      \textbf{Justification:} This test case ensures the application only accepts supported file formats and only begins processing 
      these formats. This test case acts as a preventative measure against further error progogation through the file processing stage.\\
      \textbf{How Test Was Performed:}
      \begin{enumerate}
          \item Select a prepared audio sample file.
          \item Upload the audio file for transcription.
          \item Confirm the application accepts the file through success message or by entrance into the file processing state.
      \end{enumerate}
      \textbf{Result:}
  
  \item \textbf{Test for Incorrect File Formats} \\
    \newline
    \textbf{Test ID:} FR-AR1-3-2 \\
    \textbf{Control:} Automatic \\
    \textbf{Initial State:} Application is open and idle, awaiting audio file upload from the user. \\
    \textbf{Input:} Non-audio file (e.g., \texttt{.PDF}, \texttt{.MP4}, \texttt{.JPEG}, etc.) \\
    \textbf{Expectd Output:} Denial of upload attempt with error message. \\
    \textbf{Actual Output:} \\
    \textbf{Test Case Derivation:} For validation of functional requirements FR-AR1 and FR-AR3 in section 9.1 of the
    \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
    \textbf{Justification:} Complements test case FR-AR1-3-1. It will ensure that various, unsupported file formats are 
    not accepted by the application. \\
    \textbf{How Test Was Performed:}
    \begin{enumerate}
        \item Select a prepared file of an unsupported format (i.e. non-audio file format).
        \item Upload the file for transcription.
        \item Confirm the application denies the file and provides an error message that specifies the unsupported file format.
    \end{enumerate}
    \textbf{Result:}
  
  \item \textbf{Test User Device Microphone} \\
  \newline
  \textbf{Test ID:} FR-AR2 \\
  \textbf{Control:} Manual \\
  \textbf{Initial State:} Application is open and idle, user has navigated to the audio recording interface and microphone 
  permissions have been granted. \\
  \textbf{Input:} Audio recorded by the user device’s microphone. \\
  \textbf{Expected Output:} The application captures the correct audio and saves it in a format processable by the application 
  (e.g., \texttt{.WAV}). \\
  \textbf{Actual Output:} \\
  \textbf{Test Case Derivation:} For validation of functional requirement FR-AR2 in section 9.1 of the 
  \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. Guarentees that in addition to file uploads, 
  the user is able to capture raw, custom audio with their device hardware. \\
  \textbf{Justification:} It also validates that the audio is saved in a compatitble format for processing.\\
  \textbf{How Test Was Performed:}
  \begin{enumerate}
      \item Navigate to the application’s audio recording interface.
      \item Start a recording using the application’s “Record” element.
      \item Wait for 10 seconds and stop the recording.
      \item Confirm that the audio was recorded through:
      \begin{itemize}
          \item Playback using an audio player on the device.
          \item File metadata analysis (duration, file size, etc.).
          \item Waveform inspection using an external tool (e.g., Audacity).
      \end{itemize}
      \item Confirm that the captured audio matches the expected input via playback, metadata, and/or waveform inspection.
  \end{enumerate}
  \textbf{Result:}
  
  \item \textbf{Test Generated Score Alignment with Selected Instrument} \\
    \newline
    \textbf{Test ID:} FR-AR4 \\
    \textbf{Control:} Automatic \\
    \textbf{Initial State:} Application is running and idle, pre-transcription state awaiting input. \\
    \textbf{Input:} Sample audio file or user-recorded audio and selected instrument type. \\
    \textbf{Expected Output:} A generated sheet music file in MusicXML format that aligns with the selected instrument’s key signature 
    and note pitches. \\
    \textbf{Actual Output:} \\
    \textbf{Test Case Derivation:} For validation of functional requirement FR-AR4 in section 9.1 of the 
    \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}.\\
    \textbf{Justification:} Matching an instrument's specific key and pitch requirements is essential for sheet music accuracy. \\
    \textbf{How Test Was Performed:}
    \begin{enumerate}
        \item Select and submit an instrument type within the application.
        \item Upload an audio input for the selected instrument.
        \item Upon transcription completion, parse the generated score.
        \item Verify that the key signature and note pitches match the expected result for the selected instrument.
    \end{enumerate}
  \end{enumerate}
  \textbf{Result:}

  \subsection{Signal Processing and Element Identification}
  \begin{enumerate}
    \item \textbf{Test Effect of Increased Noise in Audio Input} \\
      \newline
      \textbf{Test ID:} FR-SP1 \\
      \textbf{Control:} Automatic \\
      \textbf{Initial State:} Application is running and idle, awaiting file upload from the user. \\
      \textbf{Input:} Two sample audio files—one unedited, the other with ~10\% noise interference. \\
      \textbf{Expected Output:} Two identical sheet music files in MusicXML format. \\
      \textbf{Actual Output:} \\
      \textbf{Test Case Derivation:} For validation of functional requirement FR-SP1 in section 9.2 of the 
      \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
      \textbf{Justification:} Confirms that the application can handle expected levels of background noise in input 
      audio, and that it can maintain accuracy despite the noise.\\
      \textbf{How Test Was Performed:}
      \begin{enumerate}
          \item Upload the unedited audio file to the application and generate a sheet music file.
          \item Upload the noisy audio file and generate another sheet music file.
          \item Parse both files and identify discrepancies, if any.
      \end{enumerate}
      \textbf{Result:}
    
    \item \textbf{Test for Pitch and Rhythm Identification} \\
      \newline
      \textbf{Test ID:} FR-SP2 \\
      \textbf{Control:} Manual \\
      \textbf{Initial State:} Application is running and idle, awaiting audio input from the user. \\
      \textbf{Input:} Sample audio file or user-recorded audio with a known sheet music equivalent. \\
      \textbf{Expected Output:} Sheet music correctly identifying all notes in the input audio. \\
      \textbf{Actual Output:} \\
      \textbf{Test Case Derivation:} For validation of functional requirement FR-SP2 in section 9.2 of the 
      \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
      \textbf{Justification:} Verfies the transcription stage as well as the pitch and rhythm identification algorithms employed
      by the applications implementation.\\
      \textbf{How Test Was Performed:}
      \begin{enumerate}
          \item Prepare an audio file containing an ascending and descending C major scale.
          \item Upload the audio input to the application.
          \item Generate and save the sheet music in a viewable file format.
          \item Compare the generated sheet music visually with the sample sheet music for note discrepancies.
      \end{enumerate}
      \textbf{Result:}

    \item \textbf{Test for Key Signature and Time Signature Identification} \\
      \newline
      \textbf{Test ID:} FR-SP3 \\
      \textbf{Control:} Automatic \\
      \textbf{Initial State:} Application is running and idle, awaiting audio input from the user. \\
      \textbf{Input:} Sample or user-recorded audio file that has a known key signature and time signature. \\
      \textbf{Expectd Output:} Sheet music that has the same key signature and time signature as the input’s sheet music. \\
      \textbf{Actual Output:} \\
      \textbf{Test Case Derivation:} For validation of functional requirement FR-SP3 in section 9.2 of the 
      \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
      \textbf{Justification:} Further verifies the transcription stage and accuracy of other sheet music elements.\\
      \textbf{How Test Was Performed:}
      \begin{enumerate}
          \item Upload the sample file or recorded audio file to the application.
          \item Save the generated sheet music in MusicXML file format.
          \item Parse the generated file and extract the key signature and time signature.
          \item Compare the extracted signatures to the known input’s signatures.
      \end{enumerate}
      \textbf{Result:}

    \item \textbf{Test for Polyphonic Audio Identification} \\
      \newline
      \textbf{Test ID:} FR-SP5 \\
      \textbf{Control:} Automatic \\
      \textbf{Initial State:} Application is running and idle, awaiting audio input from the user. \\
      \textbf{Input:} Sample file or user-recorded audio that contains known chords. \\
      \textbf{Expected Output:} Sheet music file in MusicXML format that matches the input file’s chords. \\
      \textbf{Actual Output:} \\
      \textbf{Test Case Derivation:} For validation of functional requirement FR-SP5 in section 9.2 of the 
      \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
      \textbf{Justification:} Tests the application's ability to decipher and transcribe multiple simultaneous notes
      in the audio input. \\
      \textbf{How Test Was Performed:}
      \begin{enumerate}
          \item Upload the sample audio file to the application.
          \item Ensure the sample audio file includes at least two distinct chords; single notes may or may not be interleaved.
          \item Save the generated sheet music in MusicXML file format.
          \item Parse the generated file.
          \item Compare the processed and identified chords to the known input audio chords and notes.
      \end{enumerate}
      \textbf{Result:}
  \end{enumerate}
  

  \subsection{Sheet Music Generation}
  \begin{enumerate}
  \item \textbf{Test General Notation and Layout} \\
    \newline
    \textbf{Test ID:} FR-SMG1 \\
    \textbf{Control:} Automatic with manual inspection \\
    \textbf{Initial State:} Application is running and idle, awaiting audio input from the user. \\
    \textbf{Input:} Sample or user-recorded audio file with equivalent sheet music available. \\
    \textbf{Expected Output:} Sheet music using the same layout and notation as the input. \\
    \textbf{Actual Output:} \\
    \textbf{Test Case Derivation:} For validation of functional requirement FR-SMG1 in section 9.3 of the 
    \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
    \textbf{Justification:} Ensures readability and usability, using improper notation and layout defeats the purpose of 
    generating sheet music. \\
    \textbf{How Test Was Performed:}
    \begin{enumerate}
        \item Upload the sample or user-recorded audio file for transcription.
        \item Save the generated sheet music in MusicXML format and a viewable document format.
        \item Check for discrepancies:
        \begin{itemize}
            \item Parse the MusicXML file and compare it to the input file.
            \item View the document formatted file (e.g., \texttt{.PDF}) and compare it to the input’s sheet music.
        \end{itemize}
    \end{enumerate}
    \textbf{Result:}
  
  \item \textbf{Test Instrument Specific Concert Pitch} \\
    \newline
    \textbf{Test ID:} FR-SMG2 \\
    \textbf{Control:} Manual \\
    \textbf{Initial State:} Application is running and idle, awaiting audio input from the user. \\
    \textbf{Input:} Two audio files—one from a non-transposing instrument and another from a transposing instrument. \\
    \textbf{Expected Output:} Two sets of sheet music that structurally and visually match their corresponding instrument’s concert pitch. \\
    \textbf{Actual Output:} \\
    \textbf{Test Case Derivation:} For validation of functional requirement FR-SMG2 in section 9.3 of the 
    \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
    \textbf{Justification:} Some instruments are transposing while others are non-transposing, this test case confirms the application's 
    ability to support a broad range of instruments.\\
    \textbf{How Test Was Performed:}
    \begin{enumerate}
        \item Upload a non-transposing instrument’s audio file for transcription and save the generated sheet music in a 
        viewable file format.
        \item Upload a transposing instrument’s audio file for transcription and save the generated sheet music in a viewable 
        file format.
        \item Compare the two sets of sheet music to ensure appropriate notes are in concert pitch relative to the input sheet music.
    \end{enumerate}
    \textbf{Result:}
  
  \item \textbf{Test Post-Processing Edit and View Functionalities} \\
    \newline
    \textbf{Test ID:} FR-SMG3 \\
    \textbf{Control:} Manual \\
    \textbf{Initial State:} Application has just finished processing and transcribing audio input. \\
    \textbf{Input:} Edit requests, save requests, open requests. \\
    \textbf{Expected Output:} Viewable file containing sheet music that reflects the requested edits. \\
    \textbf{Actual Output:} \\
    \textbf{Test Case Derivation:} For validation of functional requirement FR-SMG3 in section 9.3 of the 
    \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
    \textbf{Justification:} Ensures that users can change any elements of the sheet music and that these 
    changes are reflected properly by the application.\\ 
    \textbf{How Test Was Performed:}
    \begin{enumerate}
        \item View the generated sheet music in the application.
        \item Perform three edit operations:
        \begin{itemize}
            \item Note deletion.
            \item Note addition.
            \item Note pitch and/or duration change.
        \end{itemize}
        \item Save the edited sheet music in a viewable file format.
        \item Open and view the edited sheet music file to confirm that changes are present and correct.
    \end{enumerate}
    \textbf{Result:}
  \end{enumerate}
  

  \subsection{User Interface (UI)}
  \begin{enumerate}
    \item \textbf{Test Application Feedback After Audio File is Uploaded} \\
      \newline
      \textbf{Test ID:} FR-UI1 \\
      \textbf{Control:} Automatic \\
      \textbf{Initial State:} Application is running and idle, awaiting audio input from the user. \\
      \textbf{Input:} A sample audio file. \\
      \textbf{Expected Output:} Visual cue(s) on the GUI in 2 seconds or less. \\
      \textbf{Actual Output:} \\
      \textbf{Test Case Derivation:} For validation of functional requirement FR-UI1 in section 9.4 of the 
      \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
      \textbf{Justification:} Validates the funcationality that contributes to the non-functional requirement of
      human-centered design principles (see Section 4.2.2.1). One of the four fundamental principles is feedback, without 
      the proper creation and display of visual feedback cues, the application does not fulfill this principle to the 
      best of its ability.\\
      \textbf{How Test Was Performed:}
      \begin{enumerate}
          \item Upload a sample audio file to the application.
          \item Start a timer and detect visual element changes on the GUI using a testing framework (e.g., Jest).
          \item Confirm the following conditions are met:
          \begin{itemize}
              \item The appropriate visual cue is detected.
              \item The elapsed time from upload start to display of visual feedback is at most 2 seconds.
          \end{itemize}
      \end{enumerate}
      \textbf{Result:}
    
    \item \textbf{Test Availability of System Documentation} \\
      \newline
      \textbf{Test ID:} FR-UI2 \\
      \textbf{Control:} Manual \\
      \textbf{Initial State:} Application is running and idle. \\
      \textbf{Input:} Text-search queries. \\
      \textbf{Expected Output:} Navigation to appropriate documentation/user guide sections. \\
      \textbf{Actual Output:} \\
      \textbf{Test Case Derivation:} For use during user testing to meet fit criteria for functional requirement FR-UI2 in section 
      9.4 of the \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
      \textbf{Justification:} Further supports usability and humanity testing (see Section 4.2.2). Without documentation, 
      users may find navigating and using the appliation difficult.\\
      \textbf{How Test Was Performed:}
      \begin{enumerate}
          \item Navigate to the location of user documentation in the application.
          \item Perform a broad text search for major application features or for anything the user requires clarification on.
      \end{enumerate}
      \textbf{Result:}
    
    \item \textbf{Test User Feedback Report Mechanism} \\
      \newline
      \textbf{Test ID:} FR-UI3 \\
      \textbf{Control:} Automatic \\
      \textbf{Initial State:} Application is running and idle, prepared to receive input through the feedback mechanism. \\
      \textbf{Input:} Plain text. \\
      \textbf{Expected Output:} GUI submission success cue and message, return of the input text. \\
      \textbf{Actual Output:} \\
      \textbf{Test Case Derivation:} For validation of functional requirement FR-UI3 in section 9.4 of the 
      \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
      \textbf{Justification:} Ensures users are able to submit basic feedback or issues and that the application provides adequate
      feedback in the form of confirmation of a successful submission.\\
      \textbf{How Test Was Performed:}
      \begin{enumerate}
          \item Submit a plain text report via the user feedback mechanism to the development team (e.g., through email).
          \item Parse through inbox messages for user feedback reports and confirm the reception of the submitted report and 
          entire plain text input.
      \end{enumerate}
  \end{enumerate}
  \textbf{Result:}

  \subsection{Save/Load}
  \begin{enumerate}
    \item \textbf{Test Application Save Function} \\
      \newline
      \textbf{Test ID:} FR-SL1 \\
      \textbf{Control:} Manual \\
      \textbf{Initial State:} Post-audio processing state with generated sheet music file(s) and original audio files accessible 
      for download. \\
      \textbf{Input:} Request to save file(s) to local drive. \\
      \textbf{Expected Output:} Non-corrupt file(s) in destination directories. \\
      \textbf{Actual Output:} \\
      \textbf{Test Case Derivation:} For validation of functional requirement FR-SL1 in section 9.5 of the 
      \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
      \textbf{Justification:} Confirms that users are able to track their progress and save sheet music and audio files to their local 
      storage without data corruption.\\
      \textbf{How Test Was Performed:}
      \begin{enumerate}
          \item Transcribe a sample audio file using the application.
          \item Request to download both the original audio and the generated sheet music to a directory on the local drive.
          \item Compare the contents of the downloaded files to their original copies to check for consistency.
      \end{enumerate}
      \textbf{Result:}
    
    \item \textbf{Test Application’s Ability to Load Existing Files} \\
      \newline
      \textbf{Test ID:} FR-SL2 \\
      \textbf{Control:} Manual \\
      \textbf{Initial State:} Application running and idle, waiting for user input to modify and/or view. \\
      \textbf{Input:} An existing audio file or existing file containing previously generated sheet music. \\
      \textbf{Expected Output:} Successful loading of files without errors. \\
      \textbf{Actual Output:} \\
      \textbf{Test Case Derivation:} For validation of functional requirement FR-SL2 in section 9.5 of the 
      \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/SRS-Volere/SRS.pdf}{SRS}. \\
      \textbf{Justification:} Complements test case FR-SL1. Ensures users can load previously saved sheet music or 
      audio files into the application without errors.\\
      \textbf{How Test Was Performed:}
      \begin{enumerate}
          \item Request to load an existing file on the local drive.
          \item Manually inspect the opened file in the editor to ensure the files appear as they were saved.
      \end{enumerate}
  \end{enumerate}
  \textbf{Result:}

\section{Nonfunctional Requirements Evaluation}

\subsection{Usability}
		
\subsection{Performance}

\subsection{etc.}

\section{Useability Survey Results}

\section{Unit Testing}

This section describes the low-level tests that were conducted to verify that the behaviour of 
functions within the system's modules are correct. The tests were created using the GTest framework.

\subsection{Helper Functions}

\texttt{std::vector<double> generateSineWave(double frequency, double sampleRate, double duration);}
\begin{longtable}{|L{3cm}|L{2cm}|L{2cm}|L{2cm}|l|}
  \hline
  \textbf{Test} & \textbf{Inputs} & \textbf{Expected Output} & \textbf{Actual Output} & \textbf{Result} \\
  \hline
  Signal Size & 440.0, 44100.0, 1.0 & Vector size of 44100 & Vector size of 44100 & \textcolor{green}{Pass} \\
  \hline
  Amplitude Consistency & 440.0, 44100.0, 1.0 & All samples between -1 and 1.0 & Vector size of 44100 & \textcolor{green}{Pass} \\
  \hline
  Phase Continuity & 440.0, 44100.0, 1.0 & All samples approximately 0 within tolerance & All samples approximately 0 within tolerance & \textcolor{green}{Pass} \\
  \hline
  Zero Duration & 440.0, 44100.0, 0.0 & Empty vector & Vector size of 44100 & \textcolor{green}{Pass} \\
  \hline
  High Frequency & 22050.0, 44100.0, 1.0 & All samples approximately 0 within tolerance & All samples approximately 0 within tolerance & \textcolor{green}{Pass} \\
  \hline
\end{longtable}


\noindent\texttt{float extractFundamentalFrequency(const std::vector<std::vector<double>>\& spectrogram, double sampleRate);}

\begin{longtable}{|L{3cm}|L{2cm}|L{2cm}|L{2cm}|l|}
  \hline
  \textbf{Test} & \textbf{Inputs} & \textbf{Expected Output} & \textbf{Actual Output} & \textbf{Result} \\
  \hline
  Single Frame Peak & \{\{0.0, ..., 1.0, ..., 0.0\}\}, 44100.0 & 100.0 & 100.0 & \textcolor{green}{Pass} \\
  \hline
  Multi-frame Competing Peaks & \{\{0.0, ..., 1.0, ..., 0.0\}, \{0.0, ..., 2.0, ..., 0.0\}\}, 44100.0 & 75.0 & 75.0 & \textcolor{green}{Pass} \\
  \hline
  Empty Spectrogram & \{\}, 44100.0 & 0.0 & 0.0 & \textcolor{green}{Pass} \\
  \hline
  Different Sample Rate & \{\{0.0, ..., 1.0, ..., 0.0\}\}, 16000.0 & 100.0 & 100.0 & \textcolor{green}{Pass} \\
  \hline
\end{longtable}

\subsection{UI Module}
Manual testing by the developers (e.g. visual inspection, etc.) was deemed more efficient and effective for this module. Consequently, unit testing tables for the UI 
module are not included in this report.\\

\subsection{Score Generation Module}
\subsubsection{MusicXML Generation}
\begin{longtable}{|L{3cm}|L{2cm}|L{2cm}|L{2cm}|l|}
  \hline
  \textbf{Test} & \textbf{Inputs} & \textbf{Expected Output} & \textbf{Actual Output} & \textbf{Result} \\
  \hline
  Note Element Creation & 
      Regular: \{"C", 0, 4, 4, "quarter", false\}
      Rest: \{"", 0, 0, 4, "quarter", true\}
      Accidental: \{"C", 1, 4, 4, "quarter", false\} &
    Valid XML note elements (non-null) & Non-null pointers & \textcolor{green}{Pass} \\
  \hline
  Measure Creation & 
      Single note: \{"C", 0, 4, 4, "quarter", false\} 
      Multi-note: \{"C", 0, 4, 4, "quarter", false\}, \{"D", 0, 4, 4, "quarter", false\},
        \{"E", 0, 4, 4, "quarter", false\}, \{"F", 0, 4, 4, "quarter", false\} 
        Mixed: \{"C", 0, 4, 4, "quarter", false\}, \{"", 0, 0, 4, "quarter", true\},
        \{"D", 0, 4, 4, "quarter", false\}, \{"", 0, 0, 8, "half", true\}
    &
    Valid XML measure elements (non-null) & Non-null pointers & \textcolor{green}{Pass} \\
  \hline
  Part Creation & 
    \{"C", 0, 4, 4, "quarter", false; "D", 0, 4, 4, "quarter", false; 
    "E", 0, 4, 4, "quarter", false; "F", 0, 4, 4, "quarter", false; 
    "G", 1, 4, 4, "quarter", false; "", 0, 0, 8, "half", true; 
    "A", 0, 4, 4, "quarter", false; "B", -1, 4, 4, "quarter", false\} &
    Valid XML part element (non-null) & Non-null pointer & \textcolor{green}{Pass} \\
  \hline
  Score Part Creation & 
    N/A & 
    Valid XML score part element (non-null) & Non-null pointer & \textcolor{green}{Pass} \\
  \hline
  All Note Types & 
    -- & 
    Generation of all note types (e.g., dotted notes, rests) & -- & \textcolor{yellow}{Pending} \\
  \hline
  Full Generation & 
      Multiple measures with standard notes, accidentals, rests,
      missing note type, and extreme octaves
    &
      Success code; File generated and non-empty
    &
    True; file non-empty & \textcolor{green}{Pass} \\
  \hline
  Empty Sequence Generation & 
    Empty note sequence & 
    Failure code; No file generated & False; No file & \textcolor{green}{Pass} \\
  \hline
\end{longtable}

\subsection{File Format Conversion Module}
Some submodules of this module were tested manually by the developers visually (e.g. mXML to SVG/PDF). \\ \\
The following tests use a common SF\_INFO configuration (1 channel, 44100 Hz, WAV/PCM\_16) and generate a 440 Hz sine wave of 1-second duration for file I/O operations.

\begin{longtable}{|L{3cm}|L{3cm}|L{2.5cm}|L{2.5cm}|l|}
  \hline
  \textbf{Test} & \textbf{Inputs} & \textbf{Expected Output} & \textbf{Actual Output} & \textbf{Result} \\
  \hline
  Read Valid File & 
    Create directory "test-data"; \newline
    SF\_INFO; \newline
    Write sine wave (440 Hz, 1 s) to "test-data/sine.wav" & 
    SF\_INFO fields match; \newline
    Data size = 44100; \newline
    Sine samples (at indices 0, 100, 1234) within floating-point tolerance & 
    SF\_INFO and data verified; \newline
    Data size = 44100; \newline
    Sine sample checks pass & \textcolor{green}{Pass} \\
  \hline
  Read Non-Existent File & 
    File: "fakefile.wav" & 
    Data vector size = 0 & 
    Data vector size = 0 & \textcolor{green}{Pass} \\
  \hline
  Read Write Read Cycle & 
    Create directory "test-data"; \newline
    Write sine wave (440 Hz, 1 s) with SF\_INFO to "test-data/sine.wav"; \newline
    Read file, then write output to "test-data/output.wav"; \newline
    Read output file & 
    SF\_INFO and data of original and output files are identical; \newline
    Data vectors equal element-wise within floating-point tolerance & 
    SF\_INFO and data match between original and output; \newline
    Data elements are not the same within floating-point tolerence & 
    \textcolor{red}{Fail} \\
  \hline
  Write Invalid Location & 
    SF\_INFO; \newline
    Data vector: 1000 samples (each 0.5); \newline
    Invalid directory: "/DNE/" & 
    No fatal failure during write operation & 
    No fatal failure encountered & \textcolor{green}{Pass} \\
  \hline
\end{longtable}

\subsection{Raw Signal Processing Module}
\subsubsection{Pre-processing}
\begin{longtable}{|L{3cm}|L{3cm}|L{2.5cm}|L{2.5cm}|l|}
  \hline
  \textbf{Test} & \textbf{Inputs} & \textbf{Expected Output} & \textbf{Actual Output} & \textbf{Result} \\
  \hline
  Single Channel Test &
    Data: \{0.5, 1.5, -2.0, 3.0\}; \newline
    Channels: 1 &
    Processed data matches input data &
    Processed data matches input data &
    \textcolor{green}{Pass} \\
  \hline
  Two Channel to Mono Conversion &
    Data: \{1.0, 2.0, 1.1, 2.1, 1.2, 2.2\}; \newline
    Channels: 2 &
    Averaged data: \{1.5, 1.6, 1.7\} &
    Averaged data: \{1.5, 1.6, 1.7\} &
    \textcolor{green}{Pass} \\
  \hline
  Three Channel to Mono Conversion &
    Data: \{1.0, 2.0, 3.0, 1.1, 2.1, 3.1\}; \newline
    Channels: 3 &
    Averaged data: \{2.0, 2.1\} &
    Fatal failure &
    \textcolor{red}{Fail} \\
  \hline
  Empty Data &
    Data: \{\}; \newline
    Channels: 2 &
    Processed data is empty &
    Processed data is empty &
    \textcolor{green}{Pass} \\
  \hline
\end{longtable}

\subsubsection{Fourier Transform and Spectrogram Creation}
\begin{longtable}{|L{3cm}|L{3cm}|L{2.5cm}|L{2.5cm}|l|}
  \hline
  \textbf{Test} & \textbf{Inputs} & \textbf{Expected Output} & \textbf{Actual Output} & \textbf{Result} \\
  \hline
  Extract Sine Wave Frequency &
    Frequency: 440.0 Hz (A4); \newline
    Duration: 1.0 s; \newline
    Sample rate: 44100.0 Hz; \newline
    Window size: 2048; \newline
    Hop size: 441 &
    Detected frequency approximately 440.0 Hz within a tolerance of 10.0 Hz &
    Detected frequency matches expected value within tolerance &
    \textcolor{green}{Pass} \\
  \hline

  Spectrogram Dimensions &
    Constant signal value: 123.0; \newline
    Duration: 0.5 s; \newline
    Sample rate: 44100.0 Hz; \newline
    Window size: 2048; \newline
    Hop size: 441 &
    Spectrogram size matches expected number of frames; \newline
    Each frame has (window size / 2 + 1) frequency bins &
    Spectrogram dimensions match expected values &
    \textcolor{green}{Pass} \\
  \hline

  Constant Signal &
    Constant signal value: 1.0; \newline
    Duration: 0.5 s; \newline
    Sample rate: 44100.0 Hz; \newline
    Window size: 2048; \newline
    Hop size: 441; \newline
    Floating-point tolerance: 1e-6 &
    Magnitude of each spectrogram bin matches the FFT of the windowed constant signal within tolerance &
    Spectrogram magnitudes match expected FFT values within tolerance &
    \textcolor{green}{Pass} \\
  \hline

  Empty Signal &
    Empty signal vector; \newline
    Window size: 2048; \newline
    Hop size: 441 &
    Empty spectrogram &
    Empty spectrogram &
    \textcolor{green}{Pass} \\
  \hline
\end{longtable}

\subsubsection{Window Functions}
\texttt{std::vector<double> generateHammingWindow(int windowSize);}\\
\begin{longtable}{|L{3cm}|L{3cm}|L{2.5cm}|L{2.5cm}|l|}
  \hline
  \textbf{Test} & \textbf{Inputs} & \textbf{Expected Output} & \textbf{Actual Output} & \textbf{Result} \\
  \hline
  Broad Window Check &
    Window size: 10 &
    Window values match expected Hamming values: \{0.08, 0.187619556165, 
    0.460121838273, 0.77, 0.972258605561, 0.972258605561, 
    0.77, 0.460121838273, 0.187619556165, 0.08\};&
    Window values match expected values within tolerance &
    \textcolor{green}{Pass} \\
  \hline
  Window Size &
    Window size: 5 &
    Window size equals 5 &
    Window size equals 5 &
    \textcolor{green}{Pass} \\
  \hline
  Window Taper Values &
    Window size: 10 &
    First and last window values match calculated Hamming values within tolerance &
    First and last window values match expected values within tolerance &
    \textcolor{green}{Pass} \\
  \hline
  Even Window Symmetry &
    Window size: 10 &
    Window is symmetric around its center &
    Window is symmetric around its center &
    \textcolor{green}{Pass} \\
  \hline
  Odd Window Symmetry &
    Window size: 11 &
    Window is symmetric around its center with a distinct middle value &
    Window is symmetric around its center with a distinct middle value &
    \textcolor{green}{Pass} \\
  \hline
  Unique Window &
    Window size: 10 &
    Two generated windows with the same size are identical &
    Two generated windows are identical &
    \textcolor{green}{Pass} \\
  \hline
  Invalid Window Size &
    Window size: 0 &
    Function throws invalid argument exception &
    Segmentation fault &
    \textcolor{red}{Fail} \\
  \hline
\end{longtable}

\noindent\texttt{std::vector<double> generateHanningWindow(int windowSize);}\\
\begin{longtable}{|L{3cm}|L{3cm}|L{2.5cm}|L{2.5cm}|l|}
  \hline
  \textbf{Test} & \textbf{Inputs} & \textbf{Expected Output} & \textbf{Actual Output} & \textbf{Result} \\
  \hline
  Broad Window Check &
    Window size: 10 &
    Window values match expected Hamming values: \{0.0, 0.11697777845, 0.413176, 0.75, 0.9698463, 
    0.9698463, 0.75, 0.413176, 0.11697778, 0.0\}; &
    Window values match expected values within tolerance &
    \textcolor{green}{Pass} \\
  \hline
  Window Size &
    Window size: 5 &
    Window size equals 5 &
    Window size equals 5 &
    \textcolor{green}{Pass} \\
  \hline
  Window Taper Values &
    Window size: 10 &
    First and last window values match calculated Hanning values within tolerance &
    First and last window values match expected values within tolerance &
    \textcolor{green}{Pass} \\
  \hline
  Even Window Symmetry &
    Window size: 10 &
    Window is symmetric around its center &
    Window is symmetric around its center &
    \textcolor{green}{Pass} \\
  \hline
  Odd Window Symmetry &
    Window size: 11 &
    Window is symmetric around its center with a distinct middle value &
    Window is symmetric around its center with a distinct middle value &
    \textcolor{green}{Pass} \\
  \hline
  Unique Window &
    Window size: 10 &
    Two generated windows with the same size are identical &
    Two generated windows are identical &
    \textcolor{green}{Pass} \\
  \hline
  Invalid Window Size &
    Window size: 0 &
    Function throws invalid argument exception &
    Segmentation fault &
    \textcolor{red}{Fail} \\
  \hline
\end{longtable}

\subsection{Audio Feature Extraction Module}
\subsubsection{Key Detection}
\begin{longtable}{|L{3cm}|L{3cm}|L{2.5cm}|L{2.5cm}|l|}
  \hline
  \textbf{Test} & \textbf{Inputs} & \textbf{Expected Output} & \textbf{Actual Output} & \textbf{Result} \\
  \hline
  Correlation of Identical Sequences &
    Data: \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}; \newline
    Data: \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}; &
    Correlation: 1.0 &
    Correlation: 1.0 &
    \textcolor{green}{Pass} \\
  \hline
  Correlation of Opposite Sequences &
    Data: \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}; \newline
    Data: \{12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1\}; &
    Correlation: -1.0 &
    Correlation: -1.0 &
    \textcolor{green}{Pass} \\
  \hline
  Extract C Major Key &
    Durations: \{6, 2, 3, 2, 4, 4, 2, 5, 2, 3, 2, 3\} &
    Key: "C" &
    Key: "C" &
    \textcolor{green}{Pass} \\
  \hline
  Extract C Minor Key &
    Durations: \{6, 2, 3, 5, 2, 3, 2, 4, 3, 2, 3, 3\} &
    Key: "c" &
    Key: "c" &
    \textcolor{green}{Pass} \\
  \hline
  Extract A Major Key &
    Durations: \{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10\} &
    Key: "A" &
    Key: "A" &
    \textcolor{green}{Pass} \\
  \hline
  Extract F\# Major Key &
    Durations: \{2, 5, 2, 3, 2, 3, 6, 2, 3, 2, 4, 4\} &
    Key: "F\#" &
    Key: "F\#" &
    \textcolor{green}{Pass} \\
  \hline
  Extract Key of Uniform Durations &
    Durations: \{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\} &
    Key: "C" &
    Key: "C" &
    \textcolor{green}{Pass} \\
  \hline
\end{longtable}

\subsection{Audio Recording and Playback Module}
Given the inherent complexity and hardware dependencies associated with this module, it 
was tested manually by the developers. As manual testing provided a more effective and contextually 
relevant validation process given each developer's unique configuration/environment.

\section{Changes Due to Testing}
\subsection{Unit Testing Results}
Unit testing identified the following issues, which were addressed upon discovery:
\begin{enumerate}
  \item \textbf{Multi-Channel Conversion Limitations:} The system's capability to handle channel conversions was 
  initially limited to two channels. This constraint was insufficient for applications requiring support 
  for more than two channels. Recognizing this limitation, we extended the functionality to accommodate 
  conversions involving more than two channels.
  \item \textbf{Window Function Input Validation:} The initial implementation lacked proper validation for inputs 
  to the Hanning and Hamming window functions. This oversight could lead to incorrect calculations during 
  the short time Fourier transform.
  \item \textbf{.WAV File Read/Write Cycle:} The mismatch between data vectors of the original and output files, and consequent 
  test failure stemmed from differences in data representation: libsndfile uses 16-bit PCM format, while our tests expected 
  double-precision floating-point numbers. The normalization process performed by libsndfile resulted in precision loss beyond
  expected floating-point tolerence values. This issue was resolved by adjusting the test expectations to account for the
  normalization process.
\end{enumerate}

\subsection{Supervisor and Proxy Feedback}
Feedback collected during the Revision 0 demonstration led to the following changes:
\begin{enumerate}
    \item \textbf{Reduction of External Library Dependencies:} To decrease reliance on external libraries that obscure DSP functionality, 
    we reverted some implementations and developed a custom core library. This library now handles DSP functionalities such as Fourier transforms, windowing, 
    peak-picking, spectral flux analysis, and filtering. This change made the project more self-contained and introduced additional opportunities for testing.
    \item \textbf{Enhanced Audio Preprocessing Techniques:} Discussion with the supervisor on topics such as band-pass filtering and related signal processing methods 
    guided the decision to use additional audio preprocessing techniques. Specifically, a triangular filter bank was implemented which improved representations of 
    spectral characteristics of the input signal, thus, enhancing the system's audio feature extraction.
    \item \textbf{Refined Product Scope:} Based on suggestions from other proxies, we narrowed and refined the product's scope to ensure thoroughly processsed
    monophonic audio rather than more complex and therefore difficult forms of audio.
    \item \textbf{Improved Repository Traceability:} Administrative feedback emphasized the importance of granular pull requests and commits to increase 
    traceability in the repository.
\end{enumerate}

\section{Automated Testing}
A GitHub Actions (GHA) workflow triggers the unit tests described in section 5 on every push and pull request to the main branch. 
Through the use of vcpkg for dependency management, CMake for configuration, and ctest for execution the project's unit tests are 
automated. This is vital for the project's CI goals as the unit tests verify the expected behaviour of important components of the 
system including signal processing, MusicXML score generation, and file format conversion. \\
The GHA workflow for automated testing is available in the ScoreGen repository at: 
\href{https://github.com/emilyperica/ScoreGen/blob/main/.github/workflows/run-tests.yml}{\texttt{.github/workflows/run-tests.yml}}.

\section{Trace to Requirements}
See traceability tables between Test Cases and Requirements in the \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/VnVPlan/VnVPlan.pdf}{VnV Plan}.
		
\section{Trace to Modules}		
See traceability tables between Test Cases and Modules in the \href{https://github.com/emilyperica/ScoreGen/blob/main/docs/VnVPlan/VnVPlan.pdf}{VnV Plan}.

\section{Code Coverage Metrics}

\bibliographystyle{plainnat}
\bibliography{../../refs/References}

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Reflection.

\input{../Reflection.tex}

\begin{enumerate}
  \item What went well while writing this deliverable? \\
  \textbf{Mark:}

  \textbf{Emily:}

  \textbf{Ian:}

  \textbf{Jackson:}

  \item What pain points did you experience during this deliverable, and how
    did you resolve them?\\
  \textbf{Mark:}

  \textbf{Emily:}

  \textbf{Ian:}

  \textbf{Jackson:}

  \item Which parts of this document stemmed from speaking to your client(s) or
  a proxy (e.g. your peers)? Which ones were not, and why?
  \item In what ways was the Verification and Validation (VnV) Plan different
  from the activities that were actually conducted for VnV?  If there were
  differences, what changes required the modification in the plan?  Why did
  these changes occur?  Would you be able to anticipate these changes in future
  projects?  If there weren't any differences, how was your team able to clearly
  predict a feasible amount of effort and the right tasks needed to build the
  evidence that demonstrates the required quality?  (It is expected that most
  teams will have had to deviate from their original VnV Plan.)
  
\end{enumerate}

\end{document}