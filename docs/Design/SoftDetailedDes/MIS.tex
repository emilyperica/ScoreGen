\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}
\usepackage{xr}
\usepackage{hyperref}
\externaldocument{../SoftArchitecture/MG}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,    % false: boxed links; true: colored links
linkcolor=red,      % color of internal links (change box color with linkbordercolor)
citecolor=blue,     % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan       % color of external links
}

\usepackage{array}

\externaldocument{../../SRS/SRS}

\input{../../Comments}
\input{../../Common}

\begin{document}

\title{Module Interface Specification for \progname{}}

\author{\authname}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
2025-01-17 & 1.0 & Initial version\\
2025-03-24 & 1.1 & \href{https://github.com/emilyperica/ScoreGen/issues/208}{Updated contents of module Uses sections}  \\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

\begin{itemize}
    \item \textbf{MG}: Module Guide
    \item \textbf{M1}: Hardware-Hiding Module
    \item \textbf{M2}: User Interface Module
    \item \textbf{M3}: Score Generation Module
    \item \textbf{M4}: Raw Signal Processing
    \item \textbf{M5}: Audio Feature Extraction (note, key, sig, etc.)
    \item \textbf{M6}: File Format Conversions Module
    \item \textbf{M7}: Audio Recording and Playback Module
    \item \textbf{SRS}: System Requirements Specifications
    
\end{itemize}

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}
This document details the Module Interface Specifications for ScoreGen. A service
designed to transcribe user-recorded musical compositions into accurate sheet music 
by determining pitch, duration, tempo, and more advanced musical features. The service 
also aims to provide a user interface to use and interact with the product. Complementary 
documents include the SRS and MG documents. The full documentation can be found on 
\href{https://github.com/emilyperica/ScoreGen}{GitHub}.

\section{Notation}

The structure of the MIS for modules comes from \citet{HoffmanAndStrooper1995},
with the addition that template modules have been adapted from
\cite{GhezziEtAl2003}.  The mathematical notation comes from Chapter 3 of
\citet{HoffmanAndStrooper1995}.  For instance, the symbol := is used for a
multiple assignment statement and conditional rules follow the form $(c_1
\Rightarrow r_1 | c_2 \Rightarrow r_2 | ... | c_n \Rightarrow r_n )$.

The following table summarizes the primitive data types used by \progname. 

\begin{center}
\renewcommand{\arraystretch}{1.2}
\noindent 
\begin{tabular}{l l p{7.5cm}} 
\toprule 
\textbf{Data Type} & \textbf{Notation} & \textbf{Description}\\ 
\midrule
character & char & a single symbol or digit\\
integer & $\mathbb{Z}$ & a number without a fractional component in (-$\infty$, $\infty$) \\
natural number & $\mathbb{N}$ & a number without a fractional component in [1, $\infty$) \\
real & $\mathbb{R}$ & any number in (-$\infty$, $\infty$)\\
float & $\text{Note}$ & a musical pitch, defined by a frequency in Hz\\ 
float & $\text{Duration}$ & the length of a note, measured in beats or fractions thereof\\ 
float & $\text{Rest}$ & a period of silence, defined by a duration\\ 
natural number & $\text{Tempo}$ & the speed of the music, measured in beats per minute (BPM) as a natural number\\ 
float & $\text{Dynamic}$ & the volume or intensity of a note as amplitude of a signal, e.g., piano (soft) or forte (loud)\\

\bottomrule
\end{tabular} 
\end{center}

\noindent
The specification of \progname \ uses some derived data types: sequences, strings, and
tuples. Sequences are lists filled with elements of the same data type. Strings
are sequences of characters. Tuples contain a list of values, potentially of
different types. In addition, \progname \ uses functions, which
are defined by the data types of their inputs and outputs. Local functions are
described by giving their type signature followed by their specification.

\section{Module Decomposition}

The following table is taken directly from the 
\href{https://github.com/emilyperica/ScoreGen/blob/main/docs/Design/SoftArchitecture/MG.pdf}
{Module Guide} document for this project.

\begin{table}[h!]
  \centering
  \begin{tabular}{p{0.3\textwidth} p{0.6\textwidth}}
  \toprule
  \textbf{Level 1} & \textbf{Level 2}\\
  \midrule

  {Hardware-Hiding Module} & -\\
  \midrule

  \multirow{3}{0.3\textwidth}{Behaviour-Hiding Module} 
  & User Interface Module \\
  & Score Generation Module \\
  & File Format Conversion Module \\
  \midrule

  \multirow{3}{0.3\textwidth}{Software Decision Module} 
  & Raw Signal Processing Module \\
  & Audio Feature Extraction Module \\
  & Audio Recording and Playback Module \\
  \bottomrule

  \end{tabular}
  \caption{Module Hierarchy}
  \label{TblMH}
\end{table}

\newpage

\section{\hyperref[mHH]{MIS of Hardware-Hiding Module}} \label{M1}

\subsection{Module}  
Hardware-Hiding Module  

\subsection{Uses}  
N/A (Hardware-Hiding Module Does not use any other modules.)

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_MICROPHONE}  
    \item \texttt{DEFAULT\_AUDIO\_OUTPUT}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{5cm}|p{2cm}|p{4cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
initializeMicrophone & None & None & InitializationError \\  
initializeAudioOutput & None & None & InitializationError \\  
readMicrophoneBuffer & None & rawAudioData & ReadError \\  
sendToAudioOutput & audioData & None & PlaybackError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}  
\begin{itemize}  
    \item \texttt{microphoneState}  
    \item \texttt{audioOutputState}  
\end{itemize}  

\subsubsection{Environment Variables}  
\begin{itemize}  
    \item \texttt{hardwareDriverLibrary}  
    \item \texttt{deviceConfig}  
\end{itemize}  

\subsubsection{Assumptions}  
\begin{itemize}  
    \item Functional hardware to take in user audio (i.e. microphone) 
    and play out audio (i.e. speaker, headphones) is available.
    \item Necessary drivers are installed.  
\end{itemize}  

\subsubsection{Access Routine Semantics}  

\noindent \texttt{initializeMicrophone}():
\begin{itemize}  
    \item \textbf{Transition:} Sets \texttt{microphoneState} to "active".  
    \item \textbf{Exception:} \texttt{InitializationError} if device fails to initialize.  
\end{itemize}  

\noindent \texttt{sendToAudioOutput(audioData)}:
\begin{itemize}  
    \item \textbf{Transition:} Sends \texttt{audioData} to hardware.  
    \item \textbf{Exception:} \texttt{PlaybackError} if playback fails.  
\end{itemize}  

\subsubsection{Local Functions}  
\begin{itemize}  
    \item \texttt{detectAvailableHardware()}  
    \item \texttt{configureDeviceSettings(deviceType)}  
\end{itemize}  

\section{\hyperref[mUI]{MIS of User Interface Module}} \label{M2}  

\subsection{Module}  
User Interface Module  

\subsection{Uses}  
Hardware-Hiding Module (M1): For accessing microphone and audio output devices. \\
Score Generation Module (M3): For displaying generated scores, and managine score customization settings. \\
File Format Conversions Module (M6): For importing and exporting files, and displaying PDFs. \\
Audio Recording and Playback Module (M7): For managing recoring sessions. \\

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_THEME}  
    \item \texttt{MAX\_UPLOAD\_SIZE}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{5cm}|p{2cm}|p{4cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
displayUploadInterface & None & None & RenderError \\  
triggerPlayback & audioData & None & PlaybackError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}  
\begin{itemize}  
    \item \texttt{currentScreen}  
    \item \texttt{userPreferences}  
\end{itemize}  

\subsubsection{Environment Variables}  
\begin{itemize}  
    \item \texttt{displayDriver}  
    \item \texttt{inputDevices}  
\end{itemize}  

\subsubsection{Assumptions}  
\begin{itemize}  
    \item User devices support modern UI rendering.  
\end{itemize}  

\subsubsection{Access Routine Semantics}  

\noindent \texttt{displayUploadInterface}():
\begin{itemize}  
    \item \textbf{Transition:} Sets \texttt{currentScreen} to "Upload".  
    \item \textbf{Exception:} \texttt{RenderError} if rendering fails.  
\end{itemize}  

\noindent \texttt{triggerPlayback(audioData)}:
\begin{itemize}  
    \item \textbf{Transition:} Initiates playback of provided \texttt{audioData}.  
    \item \textbf{Exception:} \texttt{PlaybackError} if audio fails to play.  
\end{itemize}  

\subsubsection{Local Functions}  
\begin{itemize}  
    \item \texttt{validateUserInput()}  
    \item \texttt{renderScreen(screenType)}  
\end{itemize}  

\section{\hyperref[mSG]{MIS of Score Generation Module}} \label{M3}  

\subsection{Module}  
Score Generation Module  

\subsection{Uses}  
Raw Signal Processing Module (M4): For receiving cleand audio data. \\
Audio Feature Extraction Module (M5): For extracting musical features from audio data. (Note, Tempo, Key Signature) \\
\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_FONT\_STYLE}  
    \item \texttt{DEFAULT\_PAGE\_SIZE}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{5cm}|p{4cm}|p{2cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
generateScore & noteSequence & .mxl file & GenerationError \\  
customizeScoreSettings & settings & None & ValidationError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}  
\begin{itemize}  
    \item \texttt{scoreSettings}  
\end{itemize}  

\subsubsection{Environment Variables}  
\begin{itemize}  
    \item \texttt{fileSystemAccess}  
\end{itemize}  

\subsubsection{Assumptions}  
\begin{itemize}  
    \item Input note sequences are formatted correctly.  
    \item The file system is writable for saving .mxl files.  
\end{itemize}  

\subsubsection{Access Routine Semantics}  

\noindent \texttt{generateScore(noteSequence)}:
\begin{itemize}  
    \item \textbf{Output:} An mxl file representing the musical score.  
    \item \textbf{Exception:} \texttt{GenerationError} if input is invalid.  
\end{itemize}  

\noindent \texttt{customizeScoreSettings(settings)}:
\begin{itemize}  
    \item \textbf{Transition:} Updates \texttt{scoreSettings} with new values.  
    \item \textbf{Exception:} \texttt{ValidationError} if settings are invalid.  
\end{itemize}  

\subsubsection{Local Functions}  
\begin{itemize}  
    \item \texttt{validateSettings(settings)}  
    \item \texttt{renderPDF(noteSequence, scoreSettings)}  
\end{itemize}  

\section{\hyperref[mRSM]{MIS of Raw Signal Processing Module}} \label{M4}  

\subsection{Module}  
Raw Signal Processing Module  

\subsection{Uses}  
Hardware-Hiding Module (M1): For accessing microphone and audio output devices. 

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_SAMPLING\_RATE}  
    \item \texttt{DEFAULT\_FILTER\_SETTINGS}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{4cm}|p{3cm}|p{4cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
filterSignal & rawAudioData & filteredAudioData & FilterError \\  
adjustSamplingRate & audioData, rate & resampledAudioData & ResamplingError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}  
\begin{itemize}  
    \item \texttt{currentSamplingRate}  
    \item \texttt{filterParameters}  
\end{itemize}  

\subsubsection{Environment Variables}  
\begin{itemize}  
    \item None  
\end{itemize}  

\subsubsection{Assumptions}  
\begin{itemize}  
    \item Input audio data is in a readable format.  
\end{itemize}  

\subsubsection{Access Routine Semantics}  

\noindent \texttt{filterSignal(rawAudioData)}:
\begin{itemize}  
    \item \textbf{Output:} Filters noise and returns cleaned audio data.  
    \item \textbf{Exception:} \texttt{FilterError} if filtering fails.  
\end{itemize}  

\noindent \texttt{adjustSamplingRate(audioData, rate)}:
\begin{itemize}  
    \item \textbf{Output:} Resamples audioData to the desired rate.  
    \item \textbf{Exception:} \texttt{ResamplingError} if resampling fails.  
\end{itemize}  

\subsubsection{Local Functions}  
\begin{itemize}  
    \item \texttt{computeSpectralFeatures(audioData)}
    \item \texttt{applyFilter(rawAudioData, filterParameters)}  
    \item \texttt{resample(audioData, rate)}  
\end{itemize}  

\section{\hyperref[mAFE]{MIS of Audio Feature Extraction Module}} \label{M5}  

\subsection{Module}  
Audio Feature Extraction Module  

\subsection{Uses}
Hardware-Hiding Module (M1): For accessing microphone and audio output devices. \\
Raw Signal Processing Module (M4): For receiving filtered audio data. \\
Score Generation Module (M3): To format extracted features properly \\

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_FEATURE\_SET}  
    \item \texttt{DEFAULT\_WINDOW\_SIZE}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{4.5cm}|p{4cm}|p{2.5cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
extractFeatures & processedAudioData & featureSet & ExtractionError \\  
configureFeatureSettings & settings & None & ValidationError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}  
\begin{itemize}  
    \item \texttt{featureSettings}  
\end{itemize}  

\subsubsection{Environment Variables}  
\begin{itemize}  
    \item None  
\end{itemize}  

\subsubsection{Assumptions}  
\begin{itemize}  
    \item Input audio has been processed by the Raw Signal Processing Module.  
\end{itemize}  

\subsubsection{Access Routine Semantics}  

\noindent \texttt{extractFeatures(processedAudioData)}:
\begin{itemize}  
    \item \textbf{Output:} Extracted features such as pitch, tempo, and dynamics.  
    \item \textbf{Exception:} \texttt{ExtractionError} if feature extraction fails.  
\end{itemize}  

\noindent \texttt{configureFeatureSettings(settings)}:
\begin{itemize}  
    \item \textbf{Transition:} Updates \texttt{featureSettings} with new values.  
    \item \textbf{Exception:} \texttt{ValidationError} if settings are invalid.  
\end{itemize}  

\subsubsection{Local Functions}  
\begin{itemize}  
    \item \texttt{calculateTempoDynamics(audioData)}  
\end{itemize}  

\section{\hyperref[mFFC]{MIS of File Format Conversions Module}} \label{M6}  

\subsection{Module}  
File Format Conversions Module
\subsection{Uses} 
Hardware-Hiding Module (M1): For accessing microphone and audio output devices. \\
Score Generation Module (M3): For saving generated scores as musicXML files. \\

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{SUPPORTED\_IMPORT\_FORMATS}  
    \item \texttt{SUPPORTED\_EXPORT\_FORMATS}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{3cm}|p{4cm}|p{4cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
importFile & filePath, format & mxl data & ImportError \\  
exportFile & data, format, filePath & None & ExportError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}  
\begin{itemize}  
    \item None  
\end{itemize}  

\subsubsection{Environment Variables}  
\begin{itemize}  
    \item \texttt{fileSystemAccess}  
\end{itemize}  

\subsubsection{Assumptions}  
\begin{itemize}  
    \item The specified file path exists for import operations.  
    \item The export destination is writable.  
\end{itemize}  

\subsubsection{Access Routine Semantics}  

\noindent \texttt{importFile(filePath, format)}:
\begin{itemize}  
    \item \textbf{Output:} .mxl data extracted from Raw audio input.  
    \item \textbf{Exception:} \texttt{ImportError} if the file or format is invalid.  
\end{itemize}  

\noindent \texttt{exportFile(data, format, filePath)}:
\begin{itemize}  
    \item \textbf{Output:} Saves data in the specified format at the given file path.  
    \item \textbf{Exception:} \texttt{ExportError} if writing fails.  
\end{itemize}  

\subsubsection{Local Functions}  
\begin{itemize}  
    \item \texttt{convertToRawAudio(fileData, format)}  
    \item \texttt{writeToFile(data, format, filePath)}  
\end{itemize}  

\section{\hyperref[mARP]{MIS of Audio Recording and Playback Module}} \label{M7}  

\subsection{Module}  
Audio Recording and Playback Module  

\subsection{Uses}  
Hardware-Hiding Module (M1): For accessing microphone and audio output devices. \\
Raw Signal Processing Module (M4): For filtered recorded audio, and noise reduction. \\
Audio Feature Extraction Module (M5): For extracting musical features from recorded audio. \\

\subsection{Syntax}  

\subsubsection{Exported Constants}  
\begin{itemize}
    \item \texttt{DEFAULT\_AUDIO\_FORMAT}  
    \item \texttt{MAX\_RECORDING\_DURATION}  
\end{itemize}  

\subsubsection{Exported Access Programs}  
\begin{center}  
\begin{tabular}{|p{3cm}|p{4cm}|p{4cm}|p{3.5cm}|}  
\hline  
\textbf{Name} & \textbf{Input} & \textbf{Output} & \textbf{Exceptions} \\  
\hline  
startRecording & None & None & RecordingError \\  
stopRecording & None & rawAudioData & RecordingError \\  
playAudio & audioData & None & PlaybackError \\  
\hline  
\end{tabular}  
\end{center}  

\subsection{Semantics}  

\subsubsection{State Variables}  
\begin{itemize}  
    \item \texttt{isRecording}  
    \item \texttt{currentAudioBuffer}  
\end{itemize}  

\subsubsection{Environment Variables}  
\begin{itemize}  
    \item \texttt{microphoneAccess}  
    \item \texttt{speakerOutput}  
\end{itemize}  

\subsubsection{Assumptions}  
\begin{itemize}  
    \item Microphone and speaker are functional and accessible.  
\end{itemize}  

\subsubsection{Access Routine Semantics}  

\noindent \texttt{startRecording()}:
\begin{itemize}  
    \item \textbf{Transition:} Sets \texttt{isRecording} to true and starts capturing audio from the microphone.  
    \item \textbf{Exception:} \texttt{RecordingError} if the microphone is unavailable.  
\end{itemize}  

\noindent \texttt{stopRecording()}:
\begin{itemize}  
    \item \textbf{Output:} Captured audio as raw data.  
    \item \textbf{Transition:} Sets \texttt{isRecording} to false.  
    \item \textbf{Exception:} \texttt{RecordingError} if no recording is in progress.  
\end{itemize}  

\noindent \texttt{playAudio(audioData)}:
\begin{itemize}  
    \item \textbf{Output:} Plays the specified audio data through the speaker.  
    \item \textbf{Exception:} \texttt{PlaybackError} if playback fails.  
\end{itemize}  

\subsubsection{Local Functions}  
\begin{itemize}  
    \item \texttt{captureMicrophoneInput()}  
    \item \texttt{sendToSpeaker(audioData)}  
\end{itemize}  

\newpage

\bibliographystyle{plainnat}
\bibliography{../../../refs/References}

\newpage

\section*{Appendix --- Reflection}

\input{../../Reflection.tex}

\begin{enumerate}
  \item What went well while writing this deliverable?  \\
  
    Emily: Since a lot of the code has already been written (or at least planned out), 
    the process of identifying modules and their behaviours for this deliverable went 
    quickly and made the whole process a lot simpler.\\

    Mark: This document was helpful in creating a better understanding of the future 
    of ScoreGen at a more practical, rather than conceptual level. \\

    Ian: Splitting the work and dividing into sub teams helped speed up the process of 
    breaking down the two documents and their sections. This was good for work efficiency. 
    Communication before the deadline of this deliverable was productive and informative. \\

    Jackson: I think this deliverable was a good step to lay out all of our plans for 
    our code. This will honestly benefit us in our development of the app itself, as 
    having this to look back at will benefit us greatly.  \\
  
  \item What pain points did you experience during this deliverable, and how
  did you resolve them? \\

    Emily: Making the traceability matrix between modules and anticipated changes proved
    to be a bit of a challenge. We were directed to identify anticipated changes that ideally 
    affect only a single module, which forced me to think more critically about each AC and 
    why they are needed. \\

    Mark: As some modules are in the process of completion it was difficult to define specific 
    terms that hadn’t yet been implemented, thus completing the documentation required a lot of 
    communication and assumptions. It is also highly likely that changes will need to be made in 
    future revisions of this document to align with design choices that occur later during 
    implementation. \\

    Ian:  One pain point was deciding how abstract some of the descriptions of the module 
    secrets/services in the module guide. A balance had to be struck between being able to 
    adequately describe something vs explaining too many details/choices. This was easily solved 
    by re-reading the MG template, and by taking a look at previous students’ work and how 
    they handle this. \\

    Jackson: This deliverable was due very soon after the winter break, and getting back into 
    the flow of school plus reconnecting with the group and getting everyone on the same page 
    was tough. Additionally, breaking down the modules into their specifics proved tough, as 
    creating detailed information about our implementation at this stage. At the same time, 
    the app is still being developed, which was difficult to do. \\

    
  \item Which of your design decisions stemmed from speaking to your client(s)
  or a proxy (e.g. your peers, stakeholders, potential users)? For those that
  were not, why, and where did they come from? \\

    The majority of design decisions made up until this point did not stem from speaking to clients. 
    The main decisions made such as the algorithmic choices and which file formats to support were 
    decisions made based on the team’s knowledge of signals and systems and human-computer interfacing. 
    These decisions included selecting the Fast Fourier Transform for pitch detection due to its 
    performance and efficiency and supporting widely used file formats for distribution purposes (PDF) 
    and musical representation (musicXML). \\

  \item While creating the design doc, what parts of your other documents (e.g.
  requirements, hazard analysis, etc), if any, needed to be changed, and why? \\

    N/A \\

  \item What are the limitations of your solution? Put another way, given
  unlimited resources, what could you do to make the project better? (LO\_ProbSolutions) \\

    Our project aims to create as strong an ability as possible for non-technical musicians to create 
    highly detailed notation, but there are intricacies that are extremely difficult to extract from 
    audio alone. Features like staccato, crescendo, chords, grace notes, or tempo changes are difficult 
    to differentiate from variance that occurs from regular human playing. Tackling this issue effectively 
    would probably best be done with very advanced signal processing and personally trained, or fine-tuned 
    machine learning models. Given more time, it would also be helpful to implement advanced options for 
    users to maximise precision. If for example there is a music piece with lower confidence sections, such 
    an area where there is a similar likelihood of a note being a fast-played 16th note, or a grace note, 
    it could be possible for the user to toggle through most likely interpretations with playback to determine 
    the ideal representation of their playing. \\

  \item Give a brief overview of other design solutions you considered. What
  are the benefits and tradeoffs of those other designs compared with the chosen
  design?  From all the potential options, why did you select the documented design?
  (LO\_Explores) \\

    We considered several design solutions, including purely rule-based algorithms and advanced signal processing 
    techniques. The rule-based approach would have been easier to implement but lacks the flexibility to interpret 
    complex musical nuances like dynamics and articulation. Advanced signal processing, while more capable of handling 
    these intricacies, would require more computational resources and expertise in the field. After weighing the 
    tradeoffs, we chose a hybrid approach that combines signal processing with rule-based methods. This design provides 
    a balance between accuracy, flexibility, and resource efficiency, ensuring a strong foundation for transcription 
    while leaving room for future refinement.

\end{enumerate}

\end{document}